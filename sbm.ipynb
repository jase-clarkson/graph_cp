{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Flickr\n",
    "from torch_geometric.transforms import NormalizeFeatures, RandomNodeSplit\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "import networkx as nx\n",
    "from tqdm.notebook import tqdm\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from torch_geometric.utils import homophily\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "from functools import partial\n",
    "import pickle as pkl\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('data/SBM/test.pkl', 'rb') as f:\n",
    "    test = pkl.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "homophily(test.edge_index, test.y, method='node')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "G = to_networkx(test).to_undirected()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_nbhd_weights(G, node, k, scheme='unif'):\n",
    "    # Get dict containing nodes -> shortest path to node (i.e. depth).\n",
    "    node_depth_map = pd.Series(nx.single_source_shortest_path_length(G, node, cutoff=k), name='distance')\n",
    "    node_depth_map.index.name = 'node_id'\n",
    "    node_depth_map = node_depth_map.drop(node) # Remove the node itself from list.\n",
    "    node_depth_map = node_depth_map.reset_index()\n",
    "\n",
    "    if scheme == 'geom':\n",
    "        node_depth_map['weight'] = (0.5)**(node_depth_map['distance'] - 1)  # Weight =\n",
    "    elif scheme == 'linear':\n",
    "        node_depth_map['weight'] = 1 / node_depth_map['distance']\n",
    "    else:\n",
    "        node_depth_map['weight'] = 1\n",
    "    return node_depth_map"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp_path = 'experiments/16-03-2023_18-52-02_SBM'\n",
    "\n",
    "preds_path = os.path.join(exp_path, 'preds.pkl')\n",
    "with open(preds_path, 'rb') as f:\n",
    "    preds = pkl.load(f)\n",
    "preds = pd.DataFrame(preds)\n",
    "test_x = pd.DataFrame(test.x.numpy())\n",
    "test_y = pd.DataFrame(test.y.numpy())\n",
    "\n",
    "print(len(preds))\n",
    "print(len(test_x))\n",
    "print(len(test_y))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_y.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "probs = test_y.value_counts() / len(test_y)\n",
    "probs.name = 'Proportion'\n",
    "probs.index.name = 'Class'\n",
    "probs\n",
    "sum(probs**2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Compute the NAPS prediction set for each node in advance.\n",
    "alpha = 0.1\n",
    "quantiles_nb = []\n",
    "def calibrate_nbhd(node, scheme='unif'):\n",
    "    nbs = get_nbhd_weights(G, node, k=2, scheme=scheme)\n",
    "    nb_ids = nbs['node_id'].values\n",
    "    weights = nbs['weight'].values\n",
    "    quantile = calibrate_weighted(preds.loc[nb_ids].values,\n",
    "                         np.squeeze(test_y.loc[nb_ids].values),\n",
    "                                  weights, alpha)\n",
    "    return {node: quantile}\n",
    "# quantiles_nb = process_map(calibrate_nbhd, list(G.nodes), max_workers=12)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def precompute_naps_sets(scheme):\n",
    "    f = partial(calibrate_nbhd, scheme=scheme)\n",
    "    quantiles_nb = process_map(f, list(G.nodes), max_workers=12)\n",
    "    nz = [p for p in quantiles_nb if p is not None]\n",
    "    res = {}\n",
    "    for p in nz:\n",
    "        res.update(p)\n",
    "    nbhd_quantiles = pd.Series(res, name='quantile')\n",
    "    nbhd_quantiles\n",
    "    sets_nb = predict(preds.values, nbhd_quantiles.values[:, None])\n",
    "    sets_nb = pd.Series(sets_nb, index=list(G.nodes), name='set')\n",
    "    sets_nb = pd.DataFrame(sets_nb)\n",
    "    sets_nb['set_size'] = sets_nb['set'].apply(len)\n",
    "    sets_nb['covers'] = [test_y.loc[i].values in sets_nb.loc[i, 'set'] for i in sets_nb.index.values]\n",
    "    return sets_nb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "naps_sets = precompute_naps_sets('unif')\n",
    "napsl_sets = precompute_naps_sets('linear')\n",
    "napsg_sets = precompute_naps_sets('geom')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "naps_sets.groupby('set_size').count()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_trials = 100\n",
    "n_eval = 500\n",
    "sccv_bins = [-1, 3, 9]\n",
    "nodes = list(G.nodes())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "naps_stats = []\n",
    "napsl_stats = []\n",
    "napsg_stats = []\n",
    "full_stats = []\n",
    "\n",
    "# with mp.Pool(12) as p:\n",
    "for k in tqdm(range(n_trials)):\n",
    "    ## Sample the prediction nodes.\n",
    "    pred_nodes = np.random.choice(nodes, size=n_eval, replace=False)\n",
    "    # Neighbourhood calibration is pre-computed, so just get prediction sets for them.\n",
    "    naps_stats.append(evaluate_predictions(naps_sets.loc[pred_nodes, 'set'].values,\n",
    "                                         test_x.loc[pred_nodes].values,\n",
    "                                         np.squeeze(test_y.loc[pred_nodes].values), alpha, sccv_bins\n",
    "                                         ))\n",
    "    napsl_stats.append(evaluate_predictions(napsl_sets.loc[pred_nodes, 'set'].values,\n",
    "                                         test_x.loc[pred_nodes].values,\n",
    "                                         np.squeeze(test_y.loc[pred_nodes].values), alpha, sccv_bins\n",
    "                                         ))\n",
    "    napsg_stats.append(evaluate_predictions(napsg_sets.loc[pred_nodes, 'set'].values,\n",
    "                                         test_x.loc[pred_nodes].values,\n",
    "                                         np.squeeze(test_y.loc[pred_nodes].values), alpha, sccv_bins\n",
    "                                         ))\n",
    "\n",
    "    # Full calibration\n",
    "    quantile = calibrate(preds[~preds.index.isin(pred_nodes)].values,\n",
    "                         np.squeeze(test_y[~test_y.index.isin(pred_nodes)].values), alpha)\n",
    "    sets_full = predict(preds.loc[pred_nodes].values, quantile)\n",
    "    full_stats.append(evaluate_predictions(sets_full,\n",
    "                                           test_x.loc[pred_nodes].values,\n",
    "                                           np.squeeze(test_y.loc[pred_nodes].values), alpha, sccv_bins))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nb_df = pd.DataFrame(naps_stats, columns=['coverage', 'set_size', 'cc_set_size', 'sscv'])\n",
    "nb_df['coverage'].plot(kind='hist', bins=30)\n",
    "nb_df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nb_df = pd.DataFrame(napsl_stats, columns=['coverage', 'set_size', 'cc_set_size', 'sscv'])\n",
    "nb_df['coverage'].plot(kind='hist', bins=30)\n",
    "nb_df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nb_df = pd.DataFrame(napsg_stats, columns=['coverage', 'set_size', 'cc_set_size', 'sscv'])\n",
    "nb_df['coverage'].plot(kind='hist', bins=30)\n",
    "nb_df.describe()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "full_df = pd.DataFrame(full_stats, columns=['coverage', 'set_size', 'cc_set_size', 'sscv'])\n",
    "full_df['coverage'].plot(kind='hist', bins=30)\n",
    "full_df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from random import sample\n",
    "## Split the test nodes into non-overlapping neighbourhoods\n",
    "def split_into_neighbourhoods(test_nodes):\n",
    "    test_subgraph = G.subgraph(test_nodes).copy()\n",
    "    nbhds = []\n",
    "    while test_subgraph.number_of_nodes() > 0:\n",
    "        root = sample(list(test_subgraph.nodes()), 1)[0]\n",
    "        nbhd_nodes = list(nx.single_source_shortest_path_length(test_subgraph, root, cutoff=2).keys())\n",
    "        nbhds.append(nbhd_nodes)\n",
    "        test_subgraph.remove_nodes_from(nbhd_nodes)\n",
    "    return sorted(nbhds, key=lambda x: len(x), reverse=True)[:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aps_nccvs = []\n",
    "naps_nccvs = []\n",
    "napsl_nccvs = []\n",
    "napsg_nccvs = []\n",
    "for k in tqdm(range(n_trials)):\n",
    "    np.random.shuffle(nodes)\n",
    "    n_calib = len(nodes) // 2\n",
    "    calib_nodes = nodes[:n_calib]\n",
    "    test_nodes = nodes[n_calib:]\n",
    "\n",
    "    ## Calibrate the regular CP on calibration nodes and make predictions on test nodes\n",
    "    quantile = calibrate(preds.loc[calib_nodes].values,\n",
    "                         np.squeeze(test_y.loc[calib_nodes].values), alpha)\n",
    "    sets_full = pd.Series(predict(preds.loc[test_nodes].values, quantile), index=test_nodes)\n",
    "    nbhds = split_into_neighbourhoods(test_nodes)\n",
    "    aps_nb_coverages = []\n",
    "    naps_nb_coverages = []\n",
    "    napsl_nb_coverages = []\n",
    "    napsg_nb_coverages = []\n",
    "\n",
    "    for nbhd in nbhds:\n",
    "        aps_nb_coverages.append(np.mean([test_y.loc[node].item() in sets_full[node] for node in nbhd]))\n",
    "        naps_nb_coverages.append(naps_sets.loc[nbhd, 'covers'].mean())\n",
    "        napsl_nb_coverages.append(napsl_sets.loc[nbhd, 'covers'].mean())\n",
    "        napsg_nb_coverages.append(napsg_sets.loc[nbhd, 'covers'].mean())\n",
    "\n",
    "    aps_nccv = max(np.abs(np.array(aps_nb_coverages) - (1 - alpha)))\n",
    "    naps_nccv = max(np.abs(np.array(naps_nb_coverages) - (1 - alpha)))\n",
    "    napsl_nccv = max(np.abs(np.array(napsl_nb_coverages) - (1 - alpha)))\n",
    "    napsg_nccv = max(np.abs(np.array(napsg_nb_coverages) - (1 - alpha)))\n",
    "\n",
    "    aps_nccvs.append(aps_nccv)\n",
    "    naps_nccvs.append(naps_nccv)\n",
    "    napsl_nccvs.append(napsl_nccv)\n",
    "    napsg_nccvs.append(napsg_nccv)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(aps_nccvs).describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(naps_nccvs).describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(napsl_nccvs).describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(napsg_nccvs).describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
